{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fc2662-6fdb-4764-8f47-2b6a2012f56b",
   "metadata": {},
   "source": [
    "# Python - Scenario Based Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba197f-0310-40c7-9af9-44bc18efe5b4",
   "metadata": {},
   "source": [
    "### **1. Handling Missing Data in a Dataset**\n",
    "**Scenario:** You have a dataset with missing values in multiple columns. Write a code solution to fill missing values in the \"age\" column with the mean and drop rows where the \"income\" column has null values.\n",
    "\n",
    "**Steps:**\n",
    "1. Import the necessary library (Pandas).\n",
    "2. Load or create the dataset.\n",
    "3. Use `fillna()` to replace missing values in the \"age\" column with the column's mean.\n",
    "4. Use `dropna()` to remove rows where \"income\" has null values.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Create the dataset\n",
    "data = {\n",
    "    'age': [25, None, 30, 35, None],\n",
    "    'income': [50000, None, 60000, 70000, 80000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 3: Fill missing values in 'age' with the mean\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "\n",
    "# Step 4: Drop rows where 'income' is null\n",
    "df.dropna(subset=['income'], inplace=True)\n",
    "\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Grouping Data to Calculate Average Sales**\n",
    "**Scenario:** Group sales data by region and calculate the average sales for each group.\n",
    "\n",
    "**Steps:**\n",
    "1. Create the dataset with columns for \"region\" and \"sales.\"\n",
    "2. Group the data by \"region\" using `groupby()`.\n",
    "3. Use `mean()` to calculate average sales for each group.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "data = {\n",
    "    'region': ['North', 'South', 'North', 'East', 'South'],\n",
    "    'sales': [200, 150, 300, 250, 400]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2 & 3: Group by region and calculate average sales\n",
    "avg_sales = df.groupby('region')['sales'].mean()\n",
    "\n",
    "print(\"Average Sales by Region:\")\n",
    "print(avg_sales)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Visualizing Sales Trend Over Time**\n",
    "**Scenario:** Visualize the trend of sales over time using Matplotlib.\n",
    "\n",
    "**Steps:**\n",
    "1. Create the dataset with \"date\" and \"sales\" columns.\n",
    "2. Convert the \"date\" column to datetime using `pd.to_datetime()`.\n",
    "3. Plot the sales trend using `plt.plot()`.\n",
    "4. Add title, labels, and grid for better readability.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "data = {'date': ['2023-01-01', '2023-02-01', '2023-03-01'], 'sales': [200, 300, 250]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Convert 'date' to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Step 3 & 4: Plot the sales trend\n",
    "plt.plot(df['date'], df['sales'], marker='o')\n",
    "plt.title('Sales Trend Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Cleaning Inconsistent Text Data**\n",
    "**Scenario:** Clean text values in a \"Product Category\" column to ensure consistent lowercase formatting.\n",
    "\n",
    "**Steps:**\n",
    "1. Create the dataset with inconsistent text data.\n",
    "2. Use `str.lower()` to convert all text to lowercase.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "df = pd.DataFrame({'Product Category': ['Electronics', 'fUrNiTuRe', 'Clothing', 'clothing']})\n",
    "\n",
    "# Step 2: Clean the text data\n",
    "df['Product Category'] = df['Product Category'].str.lower()\n",
    "\n",
    "print(\"Cleaned Product Categories:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Descriptive Statistics**\n",
    "**Scenario:** Compute basic descriptive statistics (mean, median, mode, and standard deviation) for the \"sales\" column.\n",
    "\n",
    "**Steps:**\n",
    "1. Create the dataset with a \"sales\" column.\n",
    "2. Use `describe()` to get basic statistics.\n",
    "3. Use `mean()`, `median()`, `mode()`, and `std()` for individual metrics.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "df = pd.DataFrame({'sales': [200, 300, 250, 200, 400]})\n",
    "\n",
    "# Step 2: Use describe() for an overview\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(df['sales'].describe())\n",
    "\n",
    "# Step 3: Compute individual statistics\n",
    "mean = df['sales'].mean()\n",
    "median = df['sales'].median()\n",
    "mode = df['sales'].mode()[0]\n",
    "std_dev = df['sales'].std()\n",
    "\n",
    "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}, Std Dev: {std_dev}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Identifying and Removing Duplicate Rows**\n",
    "**Scenario:** Identify duplicate rows and remove them.\n",
    "\n",
    "**Steps:**\n",
    "1. Create the dataset with duplicate rows.\n",
    "2. Use `duplicated()` to check for duplicate rows.\n",
    "3. Use `drop_duplicates()` to remove them.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "df = pd.DataFrame({'name': ['Alice', 'Bob', 'Alice'], 'age': [25, 30, 25]})\n",
    "\n",
    "# Step 2: Check for duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(df.duplicated())\n",
    "\n",
    "# Step 3: Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"DataFrame after removing duplicates:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Performing SQL-like Joins in Pandas**\n",
    "**Scenario:** Perform an inner join on two datasets based on the \"customer_id\" column.\n",
    "\n",
    "**Steps:**\n",
    "1. Create two datasets: \"customers\" and \"orders.\"\n",
    "2. Use `pd.merge()` to perform an inner join.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create the datasets\n",
    "customers = pd.DataFrame({'customer_id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']})\n",
    "orders = pd.DataFrame({'order_id': [101, 102, 103], 'customer_id': [1, 2, 4]})\n",
    "\n",
    "# Step 2: Perform an inner join\n",
    "merged_df = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "\n",
    "print(\"Merged DataFrame (Inner Join):\")\n",
    "print(merged_df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario 8: Merging Large Datasets with Performance Issues**\n",
    "**Question:** Suppose you have two large datasets (5 million rows each) that you need to merge based on multiple columns. The merge operation is extremely slow. How would you optimize it in Python?\n",
    "\n",
    "**Solution:**  \n",
    "- One optimization technique is to set the columns used for merging as indices beforehand, which speeds up the merge operation.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample large datasets\n",
    "df1 = pd.DataFrame({'id': range(1000000), 'value1': range(1000000)})\n",
    "df2 = pd.DataFrame({'id': range(500000, 1500000), 'value2': range(500000, 1500000)})\n",
    "\n",
    "# Optimized merge by setting index\n",
    "df1.set_index('id', inplace=True)\n",
    "df2.set_index('id', inplace=True)\n",
    "\n",
    "merged_df = df1.join(df2, how='inner')\n",
    "\n",
    "print(\"Merge completed with optimized index setting.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario 9: Parsing Dates with Inconsistent Formats**\n",
    "**Question:** You have a dataset with a \"date\" column where some values are in the format \"MM/DD/YYYY\" and others are in \"YYYY-MM-DD.\" How would you standardize the date format for analysis?  \n",
    "\n",
    "**Solution:**  \n",
    "- Use `pd.to_datetime()` to parse dates and standardize their format.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'date': ['01/31/2023', '2023-01-30', '02/01/2023']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing date format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Coerce invalid dates to NaT\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario 10: Outlier Detection and Handling in Data**\n",
    "**Question:** You find that some sales values in your dataset are unusually high or low, which may be outliers. How would you detect and handle these outliers?  \n",
    "\n",
    "**Solution:**  \n",
    "- Use the IQR (Interquartile Range) method to identify outliers.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'sales': [200, 300, 250, 20000, 400, 150]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = df['sales'].quantile(0.25)\n",
    "Q3 = df['sales'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df[(df['sales'] < (Q1 - 1.5 * IQR)) | (df['sales'] > (Q3 + 1.5 * IQR))]\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n",
    "```\n",
    "\n",
    "### **Scenario 11: Incorrect Data Types Causing Errors**\n",
    "**Question:** You receive a dataset where numeric columns are mistakenly stored as strings. This causes errors when performing calculations. How would you fix this issue?  \n",
    "\n",
    "**Solution:**  \n",
    "- Use `pd.to_numeric()` to convert the columns to numeric types.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'sales': ['200', '300', '400', '500']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'sales' to numeric\n",
    "df['sales'] = pd.to_numeric(df['sales'])\n",
    "\n",
    "print(df.dtypes)  # Verify data type conversion\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario 12: Removing Duplicate Rows with Subtle Variations**\n",
    "**Question:** You have a dataset where duplicate rows have subtle variations (like different cases or extra spaces). How would you handle such duplicates?  \n",
    "\n",
    "**Solution:**  \n",
    "- Clean text data by stripping spaces and converting to lowercase before removing duplicates.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'name': ['Alice ', 'alice', 'Bob', 'bob  ']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize text and remove duplicates\n",
    "df['name'] = df['name'].str.strip().str.lower()\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Cleaned DataFrame without duplicates:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario 13: Pivoting Data for Better Analysis**\n",
    "**Question:** You are given a dataset with sales data, and your manager wants a summary table showing the total sales per region and product category. How would you pivot the data in Python?  \n",
    "\n",
    "**Solution:**  \n",
    "- Use `pivot_table()` to summarize the data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'region': ['North', 'South', 'North', 'East', 'South'],\n",
    "    'category': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'sales': [200, 150, 300, 250, 400]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivoting the data\n",
    "pivot_table = df.pivot_table(values='sales', index='region', columns='category', aggfunc='sum', fill_value=0)\n",
    "print(\"Pivot Table:\")\n",
    "print(pivot_table)\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
